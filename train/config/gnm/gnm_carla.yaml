project_name: gnm
run_name: gnm_public

# training setup
use_wandb: True # set to false if you don't want to log to wandb
train: True
batch_size: 10
eval_batch_size: 5
epochs: 50
gpu_ids: [0] # list of gpu ids to use
num_workers: 4
lr: 1e-5

optimizer: adam
seed: 0

# model params
model_type: gnm-modified
obs_encoding_size: 1024
goal_encoding_size: 1024

# normalization for the action space
normalize: True

# context
context_type: temporal
context_size: 5

# tradeoff between action and distance prediction loss
alpha: 0.6

#load run
# load_run: carla


# distance bounds for distance and action and distance predictions 
distance:
  min_dist_cat: 0
  max_dist_cat: 5
action:
  min_dist_cat: 2
  max_dist_cat: 5
close_far_threshold: 5 # distance threshold used to seperate the close and the far  subgoals that are sampled per datapoint

# action output params
len_traj_pred: 5
learn_angle: True

# dataset specific parameters
image_size: [85, 64] # width, height
datasets:
  carla:
    data_folder: ../carla_trajectories # path to the dataset
    train: gnm_train/data/data_splits/carla_trajectories/train/ # path to the train dir with traj_names.txt
    test: gnm_train/data/data_splits/carla_trajectories/test/ # path to the test dir with traj_names.txt
    end_slack: 0 # because many trajectories end in collisions
    goals_per_obs: 2 # how many goals are sampled per observation
    negative_mining: True # negative mining from the ViNG paper (Shah et al.)
  go_stanford:
    data_folder: ../go_stanford
    train: gnm_train/data/data_splits/go_stanford/train/
    test: gnm_train/data/data_splits/go_stanford/test/
    end_slack: 0
    goals_per_obs: 2 # increase dataset size
    negative_mining: True

# logging stuff
print_log_freq: 100 # in iterations
image_log_freq: 1000 # in iterations
num_images_log: 8 # number of images to log in a logging iteration
pairwise_test_freq: 10 # in epochs
